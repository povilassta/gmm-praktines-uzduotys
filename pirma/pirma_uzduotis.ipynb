{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Written by: Povilas Stašys (1812991)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qzs5vkiDH0I0"
      },
      "source": [
        "1. Installing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzcW3N5BM8B3",
        "outputId": "847cb7d8-e779-4c3f-f903-a334f03dd875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openimages in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (0.0.1)\n",
            "Requirement already satisfied: torchmetrics in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (0.11.1)\n",
            "Requirement already satisfied: cvdata in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (0.0.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (1.5.3)\n",
            "Requirement already satisfied: requests in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (2.28.2)\n",
            "Requirement already satisfied: lxml in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (4.9.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (4.64.1)\n",
            "Requirement already satisfied: boto3 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from openimages) (1.26.79)\n",
            "Requirement already satisfied: packaging in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.24.2)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from boto3->openimages) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.79 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from boto3->openimages) (1.29.79)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from boto3->openimages) (1.0.1)\n",
            "Requirement already satisfied: pillow in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cvdata->openimages) (9.4.0)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from cvdata->openimages) (4.7.0.72)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from pandas->openimages) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->openimages) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->openimages) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->openimages) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from requests->openimages) (3.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from tqdm->openimages) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\povil\\miniconda3\\envs\\pytorch\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->openimages) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install openimages torchmetrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugmancw49JFN"
      },
      "source": [
        "2. Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoM5bivBPHpm",
        "outputId": "2169ca11-87be-4867-8984-2011632b1bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download is starting...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-27  23:03:08 INFO Downloading 325 train images for class 'mushroom'\n",
            "100%|██████████| 325/325 [00:22<00:00, 14.68it/s]\n",
            "2023-02-27  23:03:31 INFO Downloading 334 train images for class 'strawberry'\n",
            "100%|██████████| 334/334 [00:21<00:00, 15.87it/s]\n",
            "2023-02-27  23:03:52 INFO Downloading 334 train images for class 'orange'\n",
            "100%|██████████| 334/334 [00:22<00:00, 14.99it/s]\n",
            "2023-02-27  23:04:16 INFO Downloading 9 validation images for class 'mushroom'\n",
            "100%|██████████| 9/9 [00:02<00:00,  4.27it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'mushroom': {'images_dir': 'data\\\\mushroom\\\\images'},\n",
              " 'strawberry': {'images_dir': 'data\\\\strawberry\\\\images'},\n",
              " 'orange': {'images_dir': 'data\\\\orange\\\\images'}}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from openimages.download import download_dataset\n",
        "from math import ceil\n",
        "\n",
        "data_dir = \"data\"\n",
        "total_samples = 1000\n",
        "classes = [\"Mushroom\", \"Strawberry\", \"Orange\"]\n",
        "samples_per_class = ceil(total_samples / len(classes))\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  os.makedirs(data_dir)\n",
        "  \n",
        "print(\"Download is starting...\")\n",
        "download_dataset(data_dir, classes, limit=samples_per_class)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ixoRaHT8Bi7U"
      },
      "source": [
        "3. Assign proper device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc3QqYyTIxrl",
        "outputId": "fc3a5a2b-9411-4db1-ae5c-590664b2d42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IxyHW5aJk9o8"
      },
      "source": [
        "4. Custom dataset class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MRRnQ5jkQTty"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, images_dir, transform=None):\n",
        "    self.images_dir = images_dir\n",
        "    self.transform = transform\n",
        "\n",
        "    self.class1_files = glob(self.images_dir + \"/{}/images/*.jpg\".format(classes[0].lower()))\n",
        "    self.class2_files = glob(self.images_dir + \"/{}/images/*.jpg\".format(classes[1].lower()))\n",
        "    self.class3_files = glob(self.images_dir + \"/{}/images/*.jpg\".format(classes[2].lower()))\n",
        "\n",
        "    self.class1 = len(self.class1_files)\n",
        "    self.class2 = len(self.class2_files)\n",
        "\n",
        "    self.files = self.class1_files + self.class2_files + self.class3_files\n",
        "\n",
        "    self.labels = np.zeros(len(self.files))\n",
        "    self.labels[self.class1:] = 1\n",
        "    self.labels[self.class1 + self.class2:] = 2 \n",
        "\n",
        "    self.order =  [x for x in np.random.permutation(len(self.labels))]\n",
        "    self.files = [self.files[x] for x in self.order]\n",
        "    self.labels = [self.labels[x] for x in self.order]\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.labels))\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    img_path = self.files[i]\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img_tensor = transforms.PILToTensor()(img)\n",
        "\n",
        "    if self.transform:\n",
        "      img_tensor = self.transform(img_tensor)\n",
        "            \n",
        "    y = self.labels[i]\n",
        "    return (img_tensor, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RGtbrBa2lDgY"
      },
      "source": [
        "5. Initialize Model, dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WvdZIuDudyYi"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 10\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "model = resnet50(weights=weights)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "dataset = CustomDataset(\"./data\", weights.transforms())\n",
        "dataloader = DataLoader(dataset, batch_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3dwCnme-lNxk"
      },
      "source": [
        "6. Run the images through the model and get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6hZiZclOIa_8"
      },
      "outputs": [],
      "source": [
        "model_class_ids = [weights.meta[\"categories\"].index(c.lower()) for c in classes]\n",
        "\n",
        "targets = []\n",
        "predictions = []\n",
        "\n",
        "for X, y in dataloader:\n",
        "  X, y = X.to(device), y.to(device)\n",
        "  pred = model(X)\n",
        "\n",
        "  for i, prediction in enumerate(pred):\n",
        "    class_predictions = [prediction[id].item() for id in model_class_ids]\n",
        "    predictions.append(class_predictions)\n",
        "\n",
        "    temp = np.zeros(3, dtype=int)\n",
        "    temp[int(y[i].item())] = 1\n",
        "\n",
        "    targets.append(temp)\n",
        "  \n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qUkNFqwSlX6G"
      },
      "source": [
        "7. Calculate statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcIEMhb8CBkm",
        "outputId": "19c22082-e78e-4172-8be6-c92d1b9dd387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9374583959579468\n",
            "Precision: 0.8713503479957581\n",
            "Recall: 0.9530938267707825\n",
            "F1 score: 0.9103908538818359\n"
          ]
        }
      ],
      "source": [
        "import torchmetrics\n",
        "\n",
        "predictions_tensor = torch.tensor(predictions)\n",
        "targets_tensor = torch.tensor(targets)\n",
        "\n",
        "threshold = 0.9\n",
        "\n",
        "accuracy_metric = torchmetrics.classification.MultilabelAccuracy(num_labels = 3, threshold = threshold, average = \"micro\")\n",
        "accuracy = accuracy_metric(predictions_tensor, targets_tensor).item()\n",
        "\n",
        "precision_metric = torchmetrics.classification.MultilabelPrecision(num_labels = 3, threshold = threshold, average = \"micro\")\n",
        "precision = precision_metric(predictions_tensor, targets_tensor).item()\n",
        "\n",
        "recall_metric = torchmetrics.classification.MultilabelRecall(num_labels = 3, threshold = threshold, average = \"micro\")\n",
        "recall = recall_metric(predictions_tensor, targets_tensor).item()\n",
        "\n",
        "f1_metric = torchmetrics.classification.MultilabelF1Score(num_labels = 3, threshold = threshold, average = \"micro\")\n",
        "f1 = f1_metric(predictions_tensor, targets_tensor).item()\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "d521f14f3fb86ce8092594d2edafc35729ef61c3495703c2e6a0376d4c9a6f46"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
